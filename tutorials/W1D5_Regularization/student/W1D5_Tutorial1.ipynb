{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "W1D5_Tutorial1",
      "provenance": [],
      "collapsed_sections": [
        "-PhV30moDGBj",
        "-ERb6jj0DGBj",
        "ZbHrMPJgDGBl",
        "ZK-TtZj2DGBy"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "265abdb940ae4dd6a5c2097d0ca05cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "state": {
            "_view_name": "TabView",
            "_dom_classes": [],
            "_titles": {
              "0": "Youtube",
              "1": "Bilibili"
            },
            "_model_name": "TabModel",
            "_view_module": "@jupyter-widgets/controls",
            "selected_index": 0,
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4678a9dd8d524635a0562e1ec590cc03",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab8f38590a4d4f5e8414114de0440060",
              "IPY_MODEL_17dd07cf867a4e26ad5832dc86420cd5"
            ]
          }
        },
        "4678a9dd8d524635a0562e1ec590cc03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab8f38590a4d4f5e8414114de0440060": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://youtube.com/watch?v=jhQAnIHTR6A\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/jhQAnIHTR6A?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f8e48e78850>",
                "image/jpeg": "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\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_48a94f58bea744149c930364ff484096",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "17dd07cf867a4e26ad5832dc86420cd5": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "stream",
                "metadata": {
                  "tags": []
                },
                "text": "Video available at https://www.bilibili.com/video/BV1mo4y1X76E\n",
                "stream": "stdout"
              },
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1mo4y1X76E&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                "text/plain": "<__main__.BiliVideo at 0x7f8de8f9ed50>"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_e884e55e9bd840dfa956772c03ae75d1",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "48a94f58bea744149c930364ff484096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e884e55e9bd840dfa956772c03ae75d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyronZhang13/Numpy-and-Pandas/blob/main/tutorials/W1D5_Regularization/student/W1D5_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "y2rm9UPZ6XJr"
      },
      "source": [
        "# Tutorial 1: Regularization techniques part 1\n",
        "\n",
        "**Week 1, Day 5: Regularization**\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "__Content creators:__ Ravi Teja Konkimalla, Mohitrajhu Lingan Kumaraian, Kevin Machado Gamboa, Kelson Shilling-Scrivo, Lyle Ungar\n",
        "\n",
        "__Content reviewers:__ Piyush Chauhan, Siwei Bai, Kelson Shilling-Scrivo\n",
        "\n",
        "__Content editors:__ Roberto Guidotti, Spiros Chavlis\n",
        "\n",
        "__Production editors:__ Saeed Salehi, Spiros Chavlis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "bWgfnpMk6XJt"
      },
      "source": [
        "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
        "\n",
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ByNyEBYZ6XJu"
      },
      "source": [
        "---\n",
        "# Tutorial Objectives\n",
        "\n",
        "1. Big ANNs are efficient universal approximators due to their adaptive basis functions\n",
        "2. ANNs memorize some but generalize well\n",
        "3. Regularization as shrinkage of overparameterized models: early stopping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "SQIhs7Ui6XJu",
        "outputId": "b8c520bb-48a3-4584-9566-e3a567dae0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "source": [
        "\n",
        "# @title Tutorial slides\n",
        "\n",
        "# @markdown These are the slides for the videos in this tutorial\n",
        "from IPython.display import IFrame\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/mf79a/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/mf79a/?direct%26mode=render%26action=download%26mode=render\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f8e49c790d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ZMf1BLSy6XJv"
      },
      "source": [
        "---\n",
        "# Setup\n",
        "Note that some of the code for today can take up to an hour to run. We have therefore \"hidden\" the code and shown the resulting outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "lHyT9TGA6XJw",
        "outputId": "3f27a9cb-38ed-40f1-9a91-8d2f68433f5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Install dependencies\n",
        "!sudo apt-get install -y ffmpeg > /dev/null\n",
        "!pip install imageio-ffmpeg --quiet\n",
        "\n",
        "!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n",
        "from evaltools.airtable import AirtableForm\n",
        "\n",
        "# generate airtable form\n",
        "atform = AirtableForm('appn7VdPRseSoMXEG','W1D5_T1','https://portal.neuromatchacademy.org/api/redirect/to/9c55f6cb-cdf9-4429-ac1c-ec44fe64c303')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 26.9 MB 88 kB/s \n",
            "\u001b[?25h  Building wheel for evaltools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "QZerGlLI6XJw"
      },
      "source": [
        "# Imports\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import HTML\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "R4mJEQTP6XJx"
      },
      "source": [
        "# @title Figure Settings\n",
        "import ipywidgets as widgets\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "2R9D4mw76XJy",
        "outputId": "3c3545f3-d9f3-49f0-c2bb-35b3246e7df1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Loading Animal Faces data\n",
        "import requests, os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print(\"Start downloading and unzipping `AnimalFaces` dataset...\")\n",
        "name = 'afhq'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/kgfvj/download\"\n",
        "\n",
        "if not os.path.exists(fname):\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  with open(fname, 'wb') as fh:\n",
        "    fh.write(r.content)\n",
        "\n",
        "  if os.path.exists(fname):\n",
        "    with ZipFile(fname, 'r') as zfile:\n",
        "      zfile.extractall(f\".\")\n",
        "      os.remove(fname)\n",
        "\n",
        "print(\"Download completed.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start downloading and unzipping `AnimalFaces` dataset...\n",
            "Download completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "432OsvjI6XJz",
        "outputId": "963de99e-5d11-4487-c1e8-7705da45f54e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title Loading Animal Faces Randomized data\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"Start downloading and unzipping `Randomized AnimalFaces` dataset...\")\n",
        "\n",
        "names = ['afhq_random_32x32', 'afhq_10_32x32']\n",
        "urls = [\"https://osf.io/9sj7p/download\",\n",
        "        \"https://osf.io/wvgkq/download\"]\n",
        "\n",
        "\n",
        "for i, name in enumerate(names):\n",
        "  url = urls[i]\n",
        "  fname = f\"{name}.zip\"\n",
        "\n",
        "  if not os.path.exists(fname):\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    with open(fname, 'wb') as fh:\n",
        "      fh.write(r.content)\n",
        "\n",
        "    if os.path.exists(fname):\n",
        "      with ZipFile(fname, 'r') as zfile:\n",
        "        zfile.extractall(f\".\")\n",
        "        os.remove(fname)\n",
        "\n",
        "print(\"Download completed.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start downloading and unzipping `Randomized AnimalFaces` dataset...\n",
            "Download completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "H9cz3iNt6XJ0"
      },
      "source": [
        "# @title Plotting functions\n",
        "def imshow(img):\n",
        "  img = img / 2 + 0.5     # unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.axis(False)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_weights(norm, labels, ws, title='Weight Size Measurement'):\n",
        "  plt.figure(figsize=[8, 6])\n",
        "  plt.title(title)\n",
        "  plt.ylabel('Frobenius Norm Value')\n",
        "  plt.xlabel('Model Layers')\n",
        "  plt.bar(labels, ws)\n",
        "  plt.axhline(y=norm,\n",
        "              linewidth=1,\n",
        "              color='r',\n",
        "              ls='--',\n",
        "              label='Total Model F-Norm')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def early_stop_plot(train_acc_earlystop, val_acc_earlystop, best_epoch):\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(val_acc_earlystop,label='Val - Early',c='red',ls = 'dashed')\n",
        "  plt.plot(train_acc_earlystop,label='Train - Early',c='red',ls = 'solid')\n",
        "  plt.axvline(x=best_epoch, c='green', ls='dashed',\n",
        "              label='Epoch for Max Val Accuracy')\n",
        "  plt.title('Early Stopping')\n",
        "  plt.ylabel('Accuracy (%)')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "FJdL2l9w6XJ0"
      },
      "source": [
        "# @title Set random seed\n",
        "\n",
        "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
        "\n",
        "# for DL its critical to set the random seed so that students can have a\n",
        "# baseline to compare their results to expected results.\n",
        "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "0l7p66A-6XJ1"
      },
      "source": [
        "# @title Set device (GPU or CPU). Execute `set_device()`\n",
        "# especially if torch modules used.\n",
        "\n",
        "# inform the user if the notebook uses GPU or CPU.\n",
        "\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "ha3--_ft6XJ1",
        "outputId": "64eeb0e2-8e5a-40d9-9d4b-637664ee51fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random seed 2021 has been set.\n",
            "GPU is enabled in this notebook.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "DpxMx7uu6XJ2"
      },
      "source": [
        "---\n",
        "# Section 0: Defining useful functions\n",
        "Let's start the tutorial by defining some functions which we will use frequently today, such as: `AnimalNet`, `train`, `test` and `main`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "CgNuBLHJ6XJ2"
      },
      "source": [
        "# Network Class - Animal Faces\n",
        "class AnimalNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AnimalNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(3 * 32 * 32, 128)\n",
        "    self.fc2 = nn.Linear(128, 32)\n",
        "    self.fc3 = nn.Linear(32, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "MKXze26l6XJ2"
      },
      "source": [
        "The train function takes in the current model, along with the train_loader and loss function, and updates the parameters for a single pass of the entire dataset. The test function takes in the current model after every epoch and calculates the accuracy on the test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "snOgs7y96XJ2"
      },
      "source": [
        "def train(args, model, train_loader, optimizer,\n",
        "          reg_function1=None, reg_function2=None, criterion=F.nll_loss):\n",
        "  \"\"\"\n",
        "  Trains the current inpur model using the data\n",
        "  from Train_loader and Updates parameters for a single pass\n",
        "  \"\"\"\n",
        "  device = args['device']\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    if reg_function1 is None:\n",
        "      loss = criterion(output, target)\n",
        "    elif reg_function2 is None:\n",
        "      loss = criterion(output, target)+args['lambda']*reg_function1(model)\n",
        "    else:\n",
        "      loss = criterion(output, target) + args['lambda1']*reg_function1(model) + args['lambda2']*reg_function2(model)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion=F.nll_loss, device='cpu'):\n",
        "  \"\"\"\n",
        "  Tests the current Model\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += criterion(output, target, reduction='sum').item()  # sum up batch loss\n",
        "      pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "def main(args, model, train_loader, val_loader,\n",
        "         reg_function1=None, reg_function2=None):\n",
        "  \"\"\"\n",
        "  Trains the model with train_loader and tests the learned model using val_loader\n",
        "  \"\"\"\n",
        "\n",
        "  device = args['device']\n",
        "\n",
        "  model = model.to(device)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=args['lr'],\n",
        "                        momentum=args['momentum'])\n",
        "\n",
        "  val_acc_list, train_acc_list,param_norm_list = [], [], []\n",
        "  for epoch in tqdm(range(args['epochs'])):\n",
        "    trained_model = train(args, model, train_loader, optimizer,\n",
        "                          reg_function1=reg_function1,\n",
        "                          reg_function2=reg_function2)\n",
        "    train_acc = test(trained_model, train_loader, device=device)\n",
        "    val_acc = test(trained_model, val_loader, device=device)\n",
        "    param_norm = calculate_frobenius_norm(trained_model)\n",
        "    train_acc_list.append(train_acc)\n",
        "    val_acc_list.append(val_acc)\n",
        "    param_norm_list.append(param_norm)\n",
        "\n",
        "  return val_acc_list, train_acc_list, param_norm_list, trained_model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "LxwhUPgV6XJ2"
      },
      "source": [
        "---\n",
        "# Section 1: Regularization is Shrinkage\n",
        "\n",
        "*Time estimate: ~20 mins*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "kETERtZC6XJ3",
        "outputId": "e2730a2a-2664-4d0d-8aa2-0262bd16d51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "265abdb940ae4dd6a5c2097d0ca05cb0",
            "4678a9dd8d524635a0562e1ec590cc03",
            "ab8f38590a4d4f5e8414114de0440060",
            "17dd07cf867a4e26ad5832dc86420cd5",
            "48a94f58bea744149c930364ff484096",
            "e884e55e9bd840dfa956772c03ae75d1"
          ]
        }
      },
      "source": [
        "# @title Video 1: Introduction to Regularization\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "          self.id=id\n",
        "          src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1mo4y1X76E\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"jhQAnIHTR6A\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "#add event to airtable\n",
        "atform.add_event('Video 1: Introduction to Regularization')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "265abdb940ae4dd6a5c2097d0ca05cb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "V4f00uu76XJ3"
      },
      "source": [
        "A key idea of neural nets, is that they use models that are \"too complex\" - complex enough to fit all the noise in the data. One then needs to \"regularize\" them to make the models fit complex enough, but not too complex. The more complex the model, the better it fits the training data, but if it is too complex, it generalizes less well; it memorizes the training data but is less accurate on future test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "uWBrXsNX6XJ3"
      },
      "source": [
        "# @title Video 2: Regularization as Shrinkage\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "          self.id=id\n",
        "          src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1YL411H7Dv\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"mhVbJ74upnQ\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "#add event to airtable\n",
        "atform.add_event('Video 2: Regularization as Shrinkage')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "GRvl1zJq6XJ4"
      },
      "source": [
        "One way to think about Regularization is to think in terms of the magnitude of the overall weights of the model. A model with big weights can fit more data perfectly, whereas a model with smaller weights tends to underperform on the train set but can surprisingly do very well on the test set. Having the weights too small can also be an issue as it can then underfit the model.\n",
        "\n",
        "This week we use the sum of Frobenius Norm of all the tensors in the model as a measure of the \"size of the model\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "yrIL-IK56XJ4"
      },
      "source": [
        "## Coding Exercise 1: Frobenius Norm\n",
        "Before we start, let's define the Frobenius norm, sometimes also called the Euclidean norm of an $m×n$ matrix $A$  as the square root of the sum of the absolute squares of its elements.\n",
        "\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "||A||_F= \\sqrt{\\sum_{i=1}^m\\sum_{j=1}^n|a_{ij}|^2}\n",
        "\\end{equation} \n",
        "\n",
        "This is just a measure of how big the matrix is, analogous to how big a vector is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "J1wY5Qhx6XJ4"
      },
      "source": [
        " **Hint:** Use functions `model.parameters()` or `model.named_parameters()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "PeChc3MH6XJ4",
        "outputId": "85a8abd2-4099-4e71-ed54-7c2c20c320e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def calculate_frobenius_norm(model):\n",
        "  ####################################################################\n",
        "  # Fill in all missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Define `calculate_frobenius_norm` function\")\n",
        "  ####################################################################\n",
        "  norm = 0.0\n",
        "  # Sum the square of all parameters\n",
        "  for param in model.parameters():\n",
        "    norm += torch.sum(param**2)\n",
        "\n",
        "  # Take a square root of the sum of squares of all the parameters\n",
        "  norm = norm**0.5\n",
        "  return norm\n",
        "\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 1: Frobenius Norm')\n",
        "\n",
        "# Seed added for reproducibility\n",
        "set_seed(seed=SEED)\n",
        "\n",
        "## uncomment below to test your code\n",
        "# net = nn.Linear(10, 1)\n",
        "# print(f'Frobenius Norm of Single Linear Layer: {calculate_frobenius_norm(net)}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random seed 2021 has been set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-hZO9iqm6XJ4"
      },
      "source": [
        "\n",
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D5_Regularization/solutions/W1D5_Tutorial1_Solution_1f125e8e.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "cmBzK4kw6XJ4"
      },
      "source": [
        "```\n",
        "Random seed 2021 has been set.\n",
        "Frobenius Norm of Single Linear Layer: 0.6572162508964539\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "JbHtpTU46XJ4"
      },
      "source": [
        "Apart from calculating the weight size for an entire model, we could also determine the weight size in every layer. For this, we can modify our `calculate_frobenius_norm` function as shown below. \n",
        "\n",
        "**Have a look how it works!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "QYAo2woD6XJ5"
      },
      "source": [
        "# Frobenius Norm per Layer\n",
        "def calculate_frobenius_norm(model):\n",
        "\n",
        "  # initialization of variables\n",
        "  norm, ws, labels = 0.0, [], []\n",
        "\n",
        "  # Sum all the parameters\n",
        "  for name, parameters in model.named_parameters():\n",
        "    p = torch.sum(parameters**2)\n",
        "    norm += p\n",
        "\n",
        "    ws.append((p**0.5).cpu().detach().numpy())\n",
        "    labels.append(name)\n",
        "\n",
        "  # Take a square root of the sum of squares of all the parameters\n",
        "  norm = (norm**0.5).cpu().detach().numpy()\n",
        "\n",
        "  return norm, ws, labels\n",
        "\n",
        "\n",
        "set_seed(SEED)\n",
        "net = nn.Linear(10,1)\n",
        "norm, ws, labels = calculate_frobenius_norm(net)\n",
        "print(f'Frobenius Norm of Single Linear Layer: {norm:.4f}')\n",
        "# Plots the weights\n",
        "plot_weights(norm, labels, ws)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ugPZLR1l6XJ5"
      },
      "source": [
        "Using the last function `calculate_frobenius_norm`, we can also obtain the Frobenius Norm per layer for a whole NN model and use the `plot_weigts` function to visualize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "m3oykHWY6XJ5"
      },
      "source": [
        "set_seed(seed=SEED)\n",
        "\n",
        "# Creates a new model\n",
        "model = AnimalNet()\n",
        "\n",
        "# Calculates the forbenius norm per layer\n",
        "norm, ws, labels = calculate_frobenius_norm(model)\n",
        "print(f'Frobenius Norm of Models weights: {norm:.4f}')\n",
        "\n",
        "# Plots the weights\n",
        "plot_weights(norm, labels, ws)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "cBIrTqHV6XJ5"
      },
      "source": [
        "---\n",
        "# Section 2: Overfitting\n",
        "\n",
        "*Time estimate: ~15 mins*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "bNXjWIwK6XJ5"
      },
      "source": [
        "# @title Video 3: Overparameterization and Overfitting\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "          self.id=id\n",
        "          src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1NX4y1A73i\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"-HJ_9HxY38g\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 3: Overparameterization and Overfitting')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Ve7D91wC6XJ5"
      },
      "source": [
        "## Section 2.1: Visualizing Overfitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "QhlcuKAk6XJ5"
      },
      "source": [
        "Let's create some synthetic dataset that we will use to illustrate overfitting in neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "ObzfD-5u6XJ5"
      },
      "source": [
        "set_seed(seed=SEED)\n",
        "\n",
        "# creating train data\n",
        "# input\n",
        "X = torch.rand((10, 1))\n",
        "# output\n",
        "Y = 2*X + 2*torch.empty((X.shape[0], 1)).normal_(mean=0, std=1)  # adding small error in the data\n",
        "\n",
        "#visualizing trian data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X.numpy(),Y.numpy())\n",
        "plt.xlabel('input (x)')\n",
        "plt.ylabel('output(y)')\n",
        "plt.title('toy dataset')\n",
        "plt.show()\n",
        "\n",
        "#creating test dataset\n",
        "X_test = torch.linspace(0, 1, 40)\n",
        "X_test = X_test.reshape((40, 1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "8Dts_ACe6XJ6"
      },
      "source": [
        "Let's create an overparametrized Neural Network that can fit on the dataset that we just created and train it. \n",
        "\n",
        "First, let's build the model architecture:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "Dvpk0jrm6XJ6"
      },
      "source": [
        "# Network Class - 2D\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(1, 300)\n",
        "    self.fc2 = nn.Linear(300, 500)\n",
        "    self.fc3 = nn.Linear(500, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    output = self.fc3(x)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "QYX2nr3L6XJ6"
      },
      "source": [
        "Next, let's define the different parameters for training our model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "8EPXIfvb6XJ6"
      },
      "source": [
        "set_seed(seed=SEED)\n",
        "\n",
        "# train the network on toy dataset\n",
        "model = Net()\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "iters = 0\n",
        "# Calculates frobenius before training\n",
        "normi, wsi, label = calculate_frobenius_norm(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "wHJcn50a6XJ6"
      },
      "source": [
        "At this point, we can now train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "ZCWLLoTz6XJ6"
      },
      "source": [
        "set_seed(seed=SEED)\n",
        "# initializing variables\n",
        "\n",
        "# losses\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "# model norm\n",
        "model_norm = []\n",
        "# Initializing variables to store weights\n",
        "norm_per_layer = []\n",
        "\n",
        "max_epochs = 10000\n",
        "\n",
        "running_predictions = np.empty((40, int(max_epochs / 500 + 1)))\n",
        "\n",
        "for epoch in tqdm(range(max_epochs)):\n",
        "  # frobenius norm per epoch\n",
        "  norm, pl, layer_names = calculate_frobenius_norm(model)\n",
        "\n",
        "  # training\n",
        "  model_norm.append(norm)\n",
        "  norm_per_layer.append(pl)\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  predictions = model(X)\n",
        "  loss = criterion(predictions, Y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  train_loss.append(loss.data)\n",
        "  model.eval()\n",
        "  Y_test = model(X_test)\n",
        "  loss = criterion(Y_test, 2*X_test)\n",
        "  test_loss.append(loss.data)\n",
        "\n",
        "  if (epoch % 500 == 0 or epoch == max_epochs - 1):\n",
        "    running_predictions[:, iters] = Y_test[:, 0, 0].detach().numpy()\n",
        "    iters += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "_mKmJ9zt6XJ6"
      },
      "source": [
        "Now that we have finished training, let's see how the model has evolved over the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "8MO8nTcN6XJ6"
      },
      "source": [
        "# @title Animation (Run Me!)\n",
        "\n",
        "set_seed(seed=SEED)\n",
        "# create a figure and axes\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "ax1 = plt.subplot(121)\n",
        "ax2 = plt.subplot(122)\n",
        "# organizing subplots\n",
        "plot1, = ax1.plot([],[])\n",
        "plot2 = ax2.bar([], [])\n",
        "\n",
        "\n",
        "def frame(i):\n",
        "  ax1.clear()\n",
        "  title1 = ax1.set_title('')\n",
        "  ax1.set_xlabel(\"Input(x)\")\n",
        "  ax1.set_ylabel(\"Output(y)\")\n",
        "\n",
        "  ax2.clear()\n",
        "  ax2.set_xlabel('Layer names')\n",
        "  ax2.set_ylabel('Frobenius norm')\n",
        "  title2 = ax2.set_title('Weight Measurement: Forbenius Norm')\n",
        "\n",
        "  ax1.scatter(X.numpy(),Y.numpy())\n",
        "  plot1 = ax1.plot(X_test[:,0,:].detach().numpy(), running_predictions[:,i])\n",
        "  title1.set_text(f'Epochs: {i * 500}')\n",
        "  plot2 = ax2.bar(label, norm_per_layer[i*500])\n",
        "  plt.axhline(y=model_norm[i*500], linewidth=1,\n",
        "              color='r', ls='--',\n",
        "              label=f'Norm: {model_norm[i*500]:.2f}')\n",
        "  plt.legend()\n",
        "\n",
        "  return plot1, plot2\n",
        "\n",
        "\n",
        "anim = animation.FuncAnimation(fig, frame, frames=range(20),\n",
        "                               blit=False, repeat=False,\n",
        "                               repeat_delay=10000)\n",
        "html_anim = HTML(anim.to_html5_video())\n",
        "plt.close()\n",
        "\n",
        "import IPython\n",
        "IPython.display.display(html_anim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "AfiyKkNC6XJ7"
      },
      "source": [
        "# @title Plot the train and test losses\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_loss,label='train_loss')\n",
        "plt.plot(test_loss,label='test_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('loss vs epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "maGwyWrz6XJ7"
      },
      "source": [
        "### Think! 2.1: Interpreting losses\n",
        "\n",
        "Regarding the train and test graph above, discuss among yourselves:\n",
        "\n",
        "*   What trend do you see w.r.t to train and test losses ( Where do you see the minimum of these losses?)\n",
        "*   What does it tell us about the model we trained?\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "xTvyFE9x6XJ7"
      },
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q1', text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "0vGExt2T6XJ7"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D5_Regularization/solutions/W1D5_Tutorial1_Solution_c705db1a.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "YPWsfblO6XJ7"
      },
      "source": [
        "Now let's visualize the Frobenious norm of the model as we trained. You should see that the value of weights increases over the epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "gMDW4HsM6XJ7"
      },
      "source": [
        "# @markdown Frobenious norm of the model\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(model_norm)\n",
        "plt.ylabel('norm of the model')\n",
        "plt.xlabel('epochs')\n",
        "plt.title('Size of the model vs Epochs')  # Change title to Frobenious norm of the model\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "9rNx4iAV6XJ7"
      },
      "source": [
        "Finally, you can compare the Frobenius norm per layer in the model, before and after training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "H4JLe7cR6XJ7"
      },
      "source": [
        "# @markdown Frobenius norm per layer before and after training\n",
        "normf, wsf, label = calculate_frobenius_norm(model)\n",
        "\n",
        "plot_weights(float(normi), label, wsi,\n",
        "             title='Weight Size Before Training')\n",
        "plot_weights(float(normf), label, wsf,\n",
        "             title='Weight Size After Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "XpZ9c3NE6XJ7"
      },
      "source": [
        "## Section 2.2: Overfitting on Test Dataset\n",
        "\n",
        "\n",
        "In principle we should not touch our test set until after we have chosen all our hyperparameters. Were we to use the test data in the model selection process, there is a risk that we might overfit the test data. Then we would be in serious trouble. If we overfit our training data, there is always the evaluation on test data to keep us honest. But if we overfit the test data, how would we ever know?\n",
        "\n",
        "Note that there is another kind of overfitting: you do \"honest\" fitting on one set of images or posts, or medical records, but it may not generalize to other sets of images, posts or medical records.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Nxo4faoT6XJ7"
      },
      "source": [
        "#### Validation Dataset\n",
        "A common practice to address this problem is to split our data in three ways, using a validation dataset (or validation set) to tune the hyperparameters. Ideally, we would only touch the test data once, to assess the very best model or to compare a small number of models to each other, real-world test data is seldom discarded after just one use.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "U9OuaLys6XJ8"
      },
      "source": [
        "---\n",
        "# Section 3: Memorization\n",
        "\n",
        "*Time estimate: ~20 mins*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "hg9_qP5e6XJ8"
      },
      "source": [
        "Given sufficiently large networks and enough training, Neural Networks can achieve almost 100% train accuracy by remembering each training example. This is bad, however, because it will mean that the model will fail when presented with new data.\n",
        "\n",
        "In this section we train three MLPs; one each on:\n",
        "\n",
        "\n",
        "1.   Animal Faces Dataset\n",
        "2.   A Completely Noisy Dataset (Random Shuffling of all labels)\n",
        "3.   A partially Noisy Dataset (Random Shuffling of 15% labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1Xd112ht6XJ8"
      },
      "source": [
        "Now, think for a couple of minutes as to what the train and test accuracies of each of these models might be, given that you train for sufficient time and use a powerful network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Wlmrg27j6XJ8"
      },
      "source": [
        "First, let's create the required dataloaders for all three datasets. Notice how we split the data. We train on a fraction of the dataset as it will be faster to train and will overfit more clearly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "Q8SRF2A96XJ8"
      },
      "source": [
        "# Dataloaders for the Dataset\n",
        "batch_size = 128\n",
        "classes = ('cat', 'dog', 'wild')\n",
        "\n",
        "# defining number of examples for train, val test\n",
        "len_train, len_val, len_test = 100, 100, 14430\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "data_path = pathlib.Path('.')/'afhq'  # using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "2xXwbfp26XJ8"
      },
      "source": [
        "# Dataloaders for the Original Dataset\n",
        "\n",
        "# For reproducibility\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED)\n",
        "\n",
        "img_train_data, img_val_data,_ = torch.utils.data.random_split(img_dataset,\n",
        "                                                               [len_train,\n",
        "                                                                len_val,\n",
        "                                                                len_test])\n",
        "\n",
        "# Creating train_loader and Val_loader\n",
        "train_loader = torch.utils.data.DataLoader(img_train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           num_workers=2,\n",
        "                                           worker_init_fn=seed_worker,\n",
        "                                           generator=g_seed)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(img_val_data,\n",
        "                                         batch_size=1000,\n",
        "                                         num_workers=2,\n",
        "                                         worker_init_fn=seed_worker,\n",
        "                                         generator=g_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "7foQA3E46XJ8"
      },
      "source": [
        "# Dataloaders for the Random Dataset\n",
        "\n",
        "# For reproducibility\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED + 1)\n",
        "\n",
        "# splitting randomized data into training and validation data\n",
        "data_path = pathlib.Path('.')/'afhq_random_32x32/afhq_random' # using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "random_img_train_data, random_img_val_data,_ = torch.utils.data.random_split(img_dataset, [len_train, len_val, len_test])\n",
        "\n",
        "# Randomized train and validation dataloader\n",
        "rand_train_loader = torch.utils.data.DataLoader(random_img_train_data,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=2,\n",
        "                                                worker_init_fn=seed_worker,\n",
        "                                                generator=g_seed)\n",
        "\n",
        "rand_val_loader = torch.utils.data.DataLoader(random_img_val_data,\n",
        "                                              batch_size=1000,\n",
        "                                              num_workers=2,\n",
        "                                              worker_init_fn=seed_worker,\n",
        "                                              generator=g_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "VP-nEPsZ6XJ8"
      },
      "source": [
        "# Dataloaders for the Partially Random Dataset\n",
        "\n",
        "# For reproducibility\n",
        "g_seed = torch.Generator()\n",
        "g_seed.manual_seed(SEED + 1)\n",
        "\n",
        "# Splitting data between training and validation dataset for partially randomized data\n",
        "data_path = pathlib.Path('.')/'afhq_10_32x32/afhq_10' # using pathlib to be compatible with all OS's\n",
        "img_dataset = ImageFolder(data_path/'train', transform=train_transform)\n",
        "partially_random_train_data, partially_random_val_data,_ = torch.utils.data.random_split(img_dataset, [len_train, len_val, len_test])\n",
        "\n",
        "# Training and Validation loader for partially randomized data\n",
        "partial_rand_train_loader = torch.utils.data.DataLoader(partially_random_train_data,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        num_workers=2,\n",
        "                                                        worker_init_fn=seed_worker,\n",
        "                                                        generator=g_seed)\n",
        "\n",
        "partial_rand_val_loader = torch.utils.data.DataLoader(partially_random_val_data,\n",
        "                                                      batch_size=1000,\n",
        "                                                      num_workers=2,\n",
        "                                                      worker_init_fn=seed_worker,\n",
        "                                                      generator=g_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "vhYvRSGk6XJ8"
      },
      "source": [
        "Now let's define a model which has many parameters compared to the training dataset size, and train it on these datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "tZAms5fQ6XJ9"
      },
      "source": [
        "# Network Class - Animal Faces\n",
        "class BigAnimalNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BigAnimalNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(3*32*32, 124)\n",
        "    self.fc2 = nn.Linear(124, 64)\n",
        "    self.fc3 = nn.Linear(64, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Rsq570ZO6XJ9"
      },
      "source": [
        "Before training our `BigAnimalNet()`, calculate the Frobenius norm again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "s9-sXTqC6XJ9"
      },
      "source": [
        "set_seed(seed=SEED)\n",
        "normi, wsi, label = calculate_frobenius_norm(BigAnimalNet())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tsUb-mJs6XJ9"
      },
      "source": [
        "Now, train our `BigAnimalNet()` model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "-2vK9b_p6XJ9"
      },
      "source": [
        "# Here we have 100 true train data.\n",
        "\n",
        "# Set the arguments\n",
        "args = {\n",
        "    'epochs': 200,\n",
        "    'lr': 5e-3,\n",
        "    'momentum': 0.9,\n",
        "    'device': DEVICE\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize the network\n",
        "set_seed(seed=SEED)\n",
        "model = BigAnimalNet()\n",
        "\n",
        "start_time = time.time()\n",
        "# Train the network\n",
        "val_acc_pure, train_acc_pure, _, model = main(args=args,\n",
        "                                              model=model,\n",
        "                                              train_loader=train_loader,\n",
        "                                              val_loader=val_loader)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Time to memorize the dataset: {end_time - start_time}\")\n",
        "\n",
        "# Train and Test accuracy plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(val_acc_pure, label='Val Accuracy Pure', c='red', ls='dashed')\n",
        "plt.plot(train_acc_pure, label='Train Accuracy Pure', c='red', ls='solid')\n",
        "plt.axhline(y=max(val_acc_pure), c='green', ls='dashed',\n",
        "            label='max Val accuracy pure')\n",
        "plt.title('Memorization')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "tcOkZPt76XJ9"
      },
      "source": [
        "# @markdown #### Frobenius norm for AnimalNet before and after training\n",
        "normf, wsf, label = calculate_frobenius_norm(model)\n",
        "\n",
        "plot_weights(float(normi), label, wsi, title='Weight Size Before Training')\n",
        "plot_weights(float(normf), label, wsf, title='Weight Size After Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Uza0TavE6XJ9"
      },
      "source": [
        "## Data Visualizer\n",
        "\n",
        "Before we train the model on a data with random labels, let's visualize and verify for ourselves that the data is random. Here, we have classes = (\"cat\", \"dog\", \"wild\"). \n",
        "\n",
        "We use `.permute()` method. `plt.imshow()` expects imput to be in numpy format and in the format $(P_x, P_y, 3)$, where $P_x$ and $P_y$ are the number of pixels along axis $x$ and $y$ respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "FSwh3vmk6XJ9"
      },
      "source": [
        "def visualize_data(dataloader):\n",
        "\n",
        "  for idx, (data, label) in enumerate(dataloader):\n",
        "    plt.figure(idx)\n",
        "    # Choose the datapoint you would like to visualize\n",
        "    index = 22\n",
        "\n",
        "    # choose that datapoint using index and permute the dimensions\n",
        "    # and bring the pixel values between [0, 1]\n",
        "    data = data[index].permute(1, 2, 0) * \\\n",
        "           torch.tensor([0.5, 0.5, 0.5]) + \\\n",
        "           torch.tensor([0.5, 0.5, 0.5])\n",
        "\n",
        "    # Convert the torch tensor into numpy\n",
        "    data = data.numpy()\n",
        "\n",
        "    plt.imshow(data)\n",
        "    plt.axis(False)\n",
        "    image_class = classes[label[index].item()]\n",
        "    print(f'The image belongs to : {image_class}')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Call the function\n",
        "visualize_data(rand_train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "43FLmZIh6XJ9"
      },
      "source": [
        " Now let's train the network on the shuffled data and see if it memorizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "RsX97tT36XJ9"
      },
      "source": [
        "# Here we have 100 completely shuffled train data.\n",
        "\n",
        "# Set the arguments\n",
        "args = {\n",
        "    'epochs': 200,\n",
        "    'lr': 5e-3,\n",
        "    'momentum': 0.9,\n",
        "    'device': DEVICE\n",
        "}\n",
        "\n",
        "# Intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = BigAnimalNet()\n",
        "\n",
        "# Train the model\n",
        "val_acc_random, train_acc_random, _, model = main(args,\n",
        "                                                  model,\n",
        "                                                  rand_train_loader,\n",
        "                                                  val_loader)\n",
        "\n",
        "# Train and Test accuracy plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(val_acc_pure,label='Val - Pure',c='red',ls = 'dashed')\n",
        "plt.plot(train_acc_pure,label='Train - Pure',c='red',ls = 'solid')\n",
        "plt.plot(val_acc_random,label='Val - Random',c='blue',ls = 'dashed')\n",
        "plt.plot(train_acc_random,label='Train - Random',c='blue',ls = 'solid')\n",
        "\n",
        "plt.title('Memorization')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BhQQiq-P6XJ9"
      },
      "source": [
        "Isn't it surprising to see that the NN was able to achieve 100% training accuracy on randomly shuffled labels? This is one of the reasons why training accuracy is not a good indicator of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "eA2MFpye6XJ-"
      },
      "source": [
        "---\n",
        "# Section 4: Early Stopping\n",
        "\n",
        "*Time estimate: ~20 mins*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "hb_TX0Vg6XJ-"
      },
      "source": [
        "# @title Video 4: Early Stopping\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "          self.id=id\n",
        "          src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"BV1cB4y1K777\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"72IG2bX5l30\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 4: Early Stopping')\n",
        "\n",
        "display(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "WQL2UqKq6XJ-"
      },
      "source": [
        "\n",
        "Now that we have established that the validation accuracy reaches the peak well before the model overfits, we want to somehow stop the training early. You should have also observed from the above plots that the train/test loss on real data is not very smooth and hence you might guess that the choice of epoch can play a very large role on the val/test accuracy of your model. \n",
        "\n",
        "Early stopping stops training when the validation accuracies stop increasing. \n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/static/early-stopping-machine-learning-5422207.jpg\" alt=\"Overfitting\" width=\"600\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "XUxa03A96XJ-"
      },
      "source": [
        "## Coding Exercise 4: Early Stopping\n",
        "Reimplement the main function to include early stopping as described above. Then run the code below to validate your implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "wN-smmeY6XJ-"
      },
      "source": [
        "def early_stopping_main(args, model, train_loader, val_loader):\n",
        "\n",
        "  ####################################################################\n",
        "  # Fill in all missing code below (...),\n",
        "  # then remove or comment the line below to test your function\n",
        "  raise NotImplementedError(\"Complete the early_stopping_main function\")\n",
        "  ####################################################################\n",
        "  device = args['device']\n",
        "  model = model.to(device)\n",
        "  optimizer = optim.SGD(model.parameters(),\n",
        "                        lr=args['lr'],\n",
        "                        momentum=args['momentum'])\n",
        "\n",
        "  best_acc = 0.0\n",
        "  best_epoch = 0\n",
        "\n",
        "  # Number of successive epochs that you want to wait before stopping training process\n",
        "  patience = 20\n",
        "\n",
        "  # Keps track of number of epochs during which the val_acc was less than best_acc\n",
        "  wait = 0\n",
        "\n",
        "  val_acc_list, train_acc_list = [], []\n",
        "  for epoch in tqdm(range(args['epochs'])):\n",
        "\n",
        "    # train the model\n",
        "    trained_model = ...\n",
        "\n",
        "    # calculate training accuracy\n",
        "    train_acc = ...\n",
        "\n",
        "    # calculate validation accuracy\n",
        "    val_acc = ...\n",
        "\n",
        "    if (val_acc > best_acc):\n",
        "      best_acc = val_acc\n",
        "      best_epoch = epoch\n",
        "      best_model = copy.deepcopy(trained_model)\n",
        "      wait = 0\n",
        "    else:\n",
        "      wait += 1\n",
        "\n",
        "    if (wait > patience):\n",
        "      print(f'early stopped on epoch: {epoch}')\n",
        "      break\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "    val_acc_list.append(val_acc)\n",
        "\n",
        "  return val_acc_list, train_acc_list, best_model, best_epoch\n",
        "\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Coding Exercise 4: Early Stopping')\n",
        "\n",
        "# Set the arguments\n",
        "args = {\n",
        "    'epochs': 200,\n",
        "    'lr': 5e-4,\n",
        "    'momentum': 0.99,\n",
        "    'device': DEVICE\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = AnimalNet()\n",
        "\n",
        "## Uncomment to test\n",
        "# val_acc_earlystop, train_acc_earlystop, best_model, best_epoch = early_stopping_main(args, model, train_loader, val_loader)\n",
        "# print(f'Maximum Validation Accuracy is reached at epoch: {best_epoch:2d}')\n",
        "# early_stop_plot(train_acc_earlystop, val_acc_earlystop, best_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "a7zAoxzS6XJ-"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D5_Regularization/solutions/W1D5_Tutorial1_Solution_62d845ba.py)\n",
        "\n",
        "*Example output:*\n",
        "\n",
        "<img alt='Solution hint' align='left' width=1120.0 height=832.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D5_Regularization/static/W1D5_Tutorial1_Solution_62d845ba_3.png>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rObsXzr86XJ-"
      },
      "source": [
        "## Think! 4: Early Stopping\n",
        "\n",
        "Discuss among your pod why or why not:\n",
        "\n",
        "*   Do you think early stopping can be harmful for training your network?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "S8F6xD4a6XJ-"
      },
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q3', text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "SjFpabie6XJ-"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D5_Regularization/solutions/W1D5_Tutorial1_Solution_683d27d3.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ubqlT2D06XJ_"
      },
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "In this tutorial, you have been introduced to the regularization technique, where we have described it as shrinkage. We have learned about overfitting, one of the worst caveats in deep learning, and finally we learned a method of reducing overfitting in our models called early-stopping.\n",
        "\n",
        "If you have time left, you can learn how a model behaves when is trained with randomized labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "WM-NGAuB6XJ_",
        "outputId": "12bfc47c-9b50-4881-9164-3ffb6c412501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "# @title Airtable Submission Link\n",
        "from IPython import display as IPydisplay\n",
        "IPydisplay.HTML(\n",
        "   f\"\"\"\n",
        " <div>\n",
        "   <a href= \"{atform.url()}\" target=\"_blank\">\n",
        "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/AirtableSubmissionButton.png?raw=1\"\n",
        " alt=\"button link to Airtable\" style=\"width:410px\"></a>\n",
        "   </div>\"\"\" )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              " <div>\n",
              "   <a href= \"https://portal.neuromatchacademy.org/api/redirect/to/9c55f6cb-cdf9-4429-ac1c-ec44fe64c303?data=eyJmb3JtX2lkIjogImFwcG43VmRQUnNlU29NWEVHIiwgInRhYmxlX25hbWUiOiAiVzFENV9UMSIsICJhbnN3ZXJzIjoge30sICJldmVudHMiOiBbeyJldmVudCI6ICJpbml0IiwgInRzIjogMTYyODIxMDYwNy43NDExNzgzfSwgeyJldmVudCI6ICJWaWRlbyAxOiBJbnRyb2R1Y3Rpb24gdG8gUmVndWxhcml6YXRpb24iLCAidHMiOiAxNjI4MjEwNjQ2LjkxOTYwMDV9LCB7ImV2ZW50IjogIkNvZGluZyBFeGVyY2lzZSAxOiBGcm9iZW5pdXMgTm9ybSIsICJ0cyI6IDE2MjgyMTA3MTIuNzIzMTQ0NX0sIHsiZXZlbnQiOiAidXJsIGdlbmVyYXRlZCIsICJ0cyI6IDE2MjgyMTA3MjIuMDc0NzYxMn1dfQ%3D%3D\" target=\"_blank\">\n",
              "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/AirtableSubmissionButton.png?raw=1\"\n",
              " alt=\"button link to Airtable\" style=\"width:410px\"></a>\n",
              "   </div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tvV2lunl6XJ_"
      },
      "source": [
        "---\n",
        "# Bonus: Train with randomized labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "qwgRRhg86XJ_"
      },
      "source": [
        "In this part, let's train on a partially shuffled dataset where 15% of the labels are noisy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {},
        "id": "2w-nlnpp6XJ_"
      },
      "source": [
        "# Here we have 15% partially shuffled train data.\n",
        "\n",
        "# Set the arguments\n",
        "args = {\n",
        "    'epochs': 200,\n",
        "    'lr': 5e-3,\n",
        "    'momentum': 0.9,\n",
        "    'device': DEVICE\n",
        "}\n",
        "\n",
        "# Intialize the model\n",
        "set_seed(seed=SEED)\n",
        "model = BigAnimalNet()\n",
        "\n",
        "# Train the model\n",
        "val_acc_shuffle, train_acc_shuffle, _, _, = main(args,\n",
        "                                                 model,\n",
        "                                                 partial_rand_train_loader,\n",
        "                                                 val_loader)\n",
        "\n",
        "# train and test acc plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(val_acc_shuffle, label='Val Accuracy shuffle', c='red', ls='dashed')\n",
        "plt.plot(train_acc_shuffle, label='Train Accuracy shuffle', c='red', ls='solid')\n",
        "plt.axhline(y=max(val_acc_shuffle), c='green', ls='dashed',\n",
        "            label='Max Val Accuracy shuffle')\n",
        "plt.title('Memorization')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "cZDSMGuL6XJ_"
      },
      "source": [
        "#@markdown #### Plotting them all together (Run Me!)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(val_acc_pure,label='Val - Pure',c='red',ls = 'dashed')\n",
        "plt.plot(train_acc_pure,label='Train - Pure',c='red',ls = 'solid')\n",
        "plt.plot(val_acc_random,label='Val - Random',c='blue',ls = 'dashed')\n",
        "plt.plot(train_acc_random,label='Train - Random',c='blue',ls = 'solid')\n",
        "plt.plot(val_acc_shuffle, label='Val - shuffle', c='y', ls='dashed')\n",
        "plt.plot(train_acc_shuffle, label='Train - shuffle', c='y', ls='solid')\n",
        "\n",
        "plt.title('Memorization')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "VPiJSmsP6XJ_"
      },
      "source": [
        "## Think! Bonus: Does it Generalize?\n",
        "Given that the Neural Network fit/memorize the training data perfectly:\n",
        "\n",
        "*   Do you think it generalizes well?\n",
        "*   What makes you think it does or doesn't?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tcKz6RCw6XJ_"
      },
      "source": [
        "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D5_Regularization/solutions/W1D5_Tutorial1_Solution_8f1d49a8.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "MZVjiGok6XJ_"
      },
      "source": [
        "\n",
        "Also it is interesting to note that sometimes the model trained on slightly shuffled data does slightly better than the one trained on pure data.  Shuffling some of the data is a form of regularization--one of many ways of adding noise to the training data."
      ]
    }
  ]
}